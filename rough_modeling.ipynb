{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # seaborn warning about not using data=... notation\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(25, 12)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRawData():\n",
    "    # Loading each csv into the list and concat them into one dataframe in one step \n",
    "    df = []\n",
    "\n",
    "    for file in os.listdir('data'):\n",
    "        temp = pd.read_csv(\n",
    "            f'data/{file}', \n",
    "            parse_dates = {'date': ['year', 'month', 'day', 'hour']}, \n",
    "            date_parser = lambda x: datetime.strptime(x, '%Y %m %d %H'),\n",
    "            keep_date_col = True # will be used as dummies\n",
    "        )\n",
    "\n",
    "        # Values for different stations in each city are simmilar, so we can take the mean of them \n",
    "        targetCols = [col for col in temp.columns if 'PM' in col]\n",
    "        temp['meanPM'] = temp[targetCols].mean(axis=1).round(2)\n",
    "\n",
    "        targetCols.extend(('No', 'Iprec'))\n",
    "        temp.drop(targetCols, axis=1, inplace=True)\n",
    "\n",
    "        # Adding the source of the data from the filename\n",
    "        temp['source'] = file.split('PM')[0]\n",
    "        df.append(temp)\n",
    "\n",
    "    df = pd.concat(df, axis = 0)\n",
    "\n",
    "    # Moving important columns to the front, will be usefull when categorical columns are converted to dummies\n",
    "    colsToMove = ['date', 'source', 'meanPM']\n",
    "    df = df[colsToMove + [col for col in df.columns if col not in colsToMove]]\n",
    "    df['dayOfWeek'] = df['date'].dt.dayofweek\n",
    "\n",
    "    df = df[df.date > datetime(2012, 1, 1)]\n",
    "    \n",
    "    ### Replace incorrect values with NaN ###\n",
    "    df.DEWP          = df.DEWP.replace(-9999, np.nan)\n",
    "    df.DEWP          = df.DEWP.replace(-97, np.nan)\n",
    "\n",
    "    df.HUMI          = df.HUMI.replace(-9999, np.nan)\n",
    "    df.precipitation = df.precipitation.replace(999990, np.nan)\n",
    "\n",
    "    return df.reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175315 entries, 0 to 175314\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   date           175315 non-null  datetime64[ns]\n",
      " 1   source         175315 non-null  object        \n",
      " 2   meanPM         158144 non-null  float64       \n",
      " 3   year           175315 non-null  object        \n",
      " 4   month          175315 non-null  object        \n",
      " 5   day            175315 non-null  object        \n",
      " 6   hour           175315 non-null  object        \n",
      " 7   season         175314 non-null  float64       \n",
      " 8   DEWP           174795 non-null  float64       \n",
      " 9   HUMI           174465 non-null  float64       \n",
      " 10  PRES           174452 non-null  float64       \n",
      " 11  TEMP           174797 non-null  float64       \n",
      " 12  cbwd           174802 non-null  object        \n",
      " 13  Iws            174790 non-null  float64       \n",
      " 14  precipitation  167445 non-null  float64       \n",
      " 15  dayOfWeek      175315 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1), object(6)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "loadRawData().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainTestSet():\n",
    "    df = loadRawData()\n",
    "\n",
    "    ### Fill missing values in independent variables ###\n",
    "    colsToFill = df.columns.to_list()\n",
    "    colsToFill.remove('meanPM')\n",
    "\n",
    "    # Missing values in the independent variables are rare, so they are just filled with the previous value\n",
    "    df[colsToFill] = df[colsToFill].fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "\n",
    "\n",
    "    ### Lagging the variables ###\n",
    "    independentCols = ['DEWP', 'HUMI', 'PRES', 'TEMP', 'Iws', 'precipitation']\n",
    "    df[independentCols] = df[independentCols].shift(24) # 24 hours lag\n",
    "    \n",
    "    df['meanPM_24h']  = df.groupby('source').shift(24).meanPM\n",
    "    df['meanPM_7d']   = df.groupby('source').shift(24 * 7).meanPM\n",
    "    df['meanPM_30d']  = df.groupby('source').shift(24 * 30).meanPM \n",
    "    df['meanPM_365d'] = df.groupby('source').shift(24 * 365).meanPM # later this sadly drops the first year of data\n",
    "    \n",
    "\n",
    "    ### Convert categorical to dummies ###\n",
    "    catCols = ['source', 'month', 'day', 'hour', 'season', 'cbwd', 'dayOfWeek']\n",
    "    temp = [df.drop(catCols, axis = 1)]\n",
    "    temp.extend(pd.get_dummies(df[col], prefix = col) for col in catCols)\n",
    "    df = pd.concat(temp, axis = 1)\n",
    "    \n",
    "    \n",
    "    ### Designate last year (~20%) of the data as test set ###\n",
    "    df['isTestSet'] = (df.date > datetime(2015, 1, 1)).astype(int)\n",
    "    \n",
    "    \n",
    "    ### Target col for classification ###\n",
    "    df['isDangerous'] = (df.meanPM > 100).astype(int)\n",
    "    \n",
    "    \n",
    "    ### Scale the numerical columns ###\n",
    "    numCols = ['meanPM', 'DEWP', 'HUMI', 'PRES', 'TEMP', 'Iws', 'precipitation', 'meanPM_24h', 'meanPM_7d', 'meanPM_30d', 'meanPM_365d']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[df.isTestSet == 0][numCols])\n",
    "    \n",
    "    df[numCols] = scaler.transform(df[numCols])\n",
    "    \n",
    "    \n",
    "    ### Drop rows with NaN values ###\n",
    "    # 35% of the dataset is dropped. This is just a quick analysis so it's ok\n",
    "    # In a production model, the missing values should be investigated and filled with more sophisticated methods\n",
    "    # e.g. using a moving average (but the gaps are wider than 24 hours, so it's not ideal)\n",
    "    droppedRows = df.isnull().any(axis = 1).sum()\n",
    "    percentOfTotal = (droppedRows / df.shape[0] * 100).round(2)\n",
    "    print(f'Dropping {droppedRows} ({percentOfTotal}%) rows with NaN')\n",
    "    \n",
    "    df = df[~df.isnull().any(axis = 1)].reset_index(drop = True)\n",
    "\n",
    "\n",
    "    ### Drop unnecessary columns ###\n",
    "    df = df.drop(['date', 'year'], axis = 1)\n",
    "\n",
    "\n",
    "    ### Split the data into train and test sets ###\n",
    "    independentCols = [col for col in df.columns if col not in ['meanPM', 'isTestSet', 'isDangerous']]\n",
    "    \n",
    "    X_train = df[df.isTestSet == 0][independentCols]\n",
    "    X_test  = df[df.isTestSet == 1][independentCols]\n",
    "    \n",
    "    y_train = df[df.isTestSet == 0]['meanPM']\n",
    "    y_test  = df[df.isTestSet == 1]['meanPM']\n",
    "    \n",
    "    y_train_class = df[df.isTestSet == 0]['isDangerous']\n",
    "    y_test_class  = df[df.isTestSet == 1]['isDangerous']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, y_train_class, y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>meanPM</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>season</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>HUMI</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>meanPM_24h</th>\n",
       "      <th>meanPM_7d</th>\n",
       "      <th>meanPM_30d</th>\n",
       "      <th>meanPM_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>215.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>222.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>85.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 04:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>38.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 05:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>23.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175310</th>\n",
       "      <td>2015-12-31 19:00:00</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>254.33</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>67.88</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>206.67</td>\n",
       "      <td>35.33</td>\n",
       "      <td>35.00</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175311</th>\n",
       "      <td>2015-12-31 20:00:00</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>314.33</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>67.65</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.67</td>\n",
       "      <td>37.67</td>\n",
       "      <td>31.00</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175312</th>\n",
       "      <td>2015-12-31 21:00:00</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>331.67</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>73.05</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>26.67</td>\n",
       "      <td>36.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175313</th>\n",
       "      <td>2015-12-31 22:00:00</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>287.67</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>78.94</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>198.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>25.33</td>\n",
       "      <td>31.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175314</th>\n",
       "      <td>2015-12-31 23:00:00</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>275.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>78.61</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>193.67</td>\n",
       "      <td>84.67</td>\n",
       "      <td>21.67</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175315 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    source  meanPM  year month day hour  season  \\\n",
       "0      2012-01-01 01:00:00   Beijing  215.00  2012     1   1    1     4.0   \n",
       "1      2012-01-01 02:00:00   Beijing  222.00  2012     1   1    2     4.0   \n",
       "2      2012-01-01 03:00:00   Beijing   85.00  2012     1   1    3     4.0   \n",
       "3      2012-01-01 04:00:00   Beijing   38.00  2012     1   1    4     4.0   \n",
       "4      2012-01-01 05:00:00   Beijing   23.00  2012     1   1    5     4.0   \n",
       "...                    ...       ...     ...   ...   ...  ..  ...     ...   \n",
       "175310 2015-12-31 19:00:00  Shenyang  254.33  2015    12  31   19     4.0   \n",
       "175311 2015-12-31 20:00:00  Shenyang  314.33  2015    12  31   20     4.0   \n",
       "175312 2015-12-31 21:00:00  Shenyang  331.67  2015    12  31   21     4.0   \n",
       "175313 2015-12-31 22:00:00  Shenyang  287.67  2015    12  31   22     4.0   \n",
       "175314 2015-12-31 23:00:00  Shenyang  275.00  2015    12  31   23     4.0   \n",
       "\n",
       "        DEWP   HUMI    PRES  TEMP cbwd   Iws  precipitation  dayOfWeek  \\\n",
       "0        NaN    NaN     NaN   NaN   NW   NaN            NaN          6   \n",
       "1        NaN    NaN     NaN   NaN   NW   NaN            NaN          6   \n",
       "2        NaN    NaN     NaN   NaN   NW   NaN            NaN          6   \n",
       "3        NaN    NaN     NaN   NaN   NE   NaN            NaN          6   \n",
       "4        NaN    NaN     NaN   NaN   NE   NaN            NaN          6   \n",
       "...      ...    ...     ...   ...  ...   ...            ...        ...   \n",
       "175310 -10.0  67.88  1031.0  -5.0   SE  32.0            0.0          3   \n",
       "175311 -11.0  67.65  1031.0  -6.0   SE  35.0            0.0          3   \n",
       "175312 -11.0  73.05  1032.0  -7.0   SE  37.0            0.0          3   \n",
       "175313 -11.0  78.94  1032.0  -8.0   SE   1.0            0.0          3   \n",
       "175314 -13.0  78.61  1032.0 -10.0   SE   1.0            0.0          3   \n",
       "\n",
       "        meanPM_24h  meanPM_7d  meanPM_30d  meanPM_365d  \n",
       "0              NaN        NaN         NaN          NaN  \n",
       "1              NaN        NaN         NaN          NaN  \n",
       "2              NaN        NaN         NaN          NaN  \n",
       "3              NaN        NaN         NaN          NaN  \n",
       "4              NaN        NaN         NaN          NaN  \n",
       "...            ...        ...         ...          ...  \n",
       "175310      206.67      35.33       35.00        36.00  \n",
       "175311      210.67      37.67       31.00        39.33  \n",
       "175312      210.00      65.00       26.67        36.33  \n",
       "175313      198.00      80.00       25.33        31.33  \n",
       "175314      193.67      84.67       21.67        24.00  \n",
       "\n",
       "[175315 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 62427 (35.61%) rows with NaN\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test, y_train_class, y_test_class = prepareTrainTestSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #from sklearn.pipeline import Pipeline\n",
    "    ##from sklearn.compose import ColumnTransformer\n",
    "    #from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    # sklearn pipeline did not work well\n",
    "    \n",
    "    #numCols = ['DEWP', 'HUMI', 'PRES', 'TEMP', 'Iws', 'precipitation', 'meanPM_24h', 'meanPM_7d', 'meanPM_30d', 'meanPM_365d']\n",
    "    #catCols = ['source', 'month', 'day', 'hour', 'season', 'cbwd', 'dayOfWeek']\n",
    "    #dropCols  = ['date', 'year']\n",
    "    #passCols  = ['meanPM']\n",
    "    #\n",
    "    #\n",
    "    #fullPipeline = ColumnTransformer([\n",
    "    #    ('target', 'passthrough', passCols),\n",
    "    #    ('num', StandardScaler(), numCols),\n",
    "    #    ('cat', OneHotEncoder(), catCols),\n",
    "    #    ('drop', 'drop', dropCols)\n",
    "    #]) \n",
    "    #\n",
    "    #df = pd.DataFrame(fullPipeline.fit_transform(df).todense())\n",
    "    #\n",
    "    ##df.columns = passCols + numCols + fullPipeline.named_transformers_['cat'].get_feature_names(catCols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 62427 (35.61%) rows with NaN\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, y_train_class, y_test_class = prepareTrainTestSet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356830112555304"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDummy = DummyClassifier(strategy = 'most_frequent')\n",
    "classDummy.fit(X_train, y_train_class)\n",
    "classDummy.score(X_test, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8628475804048323"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classRF = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42, verbose = 1, n_jobs = -1)\n",
    "classRF.fit(X_train, y_train_class)\n",
    "classRF.score(X_test, y_test_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.354404101653947"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regRF = RandomForestRegressor(n_estimators = 1000, max_depth = 10, random_state = 42, verbose = 1, n_jobs = -1)\n",
    "regRF.fit(X_train, y_train)\n",
    "regRF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanPM_24h         42.042290\n",
       "DEWP                7.523801\n",
       "PRES                6.090841\n",
       "meanPM_30d          4.444219\n",
       "meanPM_7d           3.275160\n",
       "cbwd_cv             2.973958\n",
       "meanPM_365d         2.892313\n",
       "source_Beijing      2.615140\n",
       "cbwd_NW             2.311247\n",
       "HUMI                1.584966\n",
       "month_1             1.512789\n",
       "TEMP                1.502663\n",
       "day_31              1.432938\n",
       "Iws                 1.409106\n",
       "day_12              1.394113\n",
       "cbwd_SE             1.035609\n",
       "source_Shenyang     0.984769\n",
       "cbwd_NE             0.931350\n",
       "month_10            0.871246\n",
       "day_6               0.832260\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance as a table with col names\n",
    "pd.Series(regRF.feature_importances_, index = X_train.columns).sort_values(ascending = False).head(20) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36ab7f9348c7d0662a1965af503f4376fbff05df74ea3a3ead8d3abcf8650cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
